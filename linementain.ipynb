{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linementain.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAt3Urg3fadD",
        "outputId": "f4de73eb-df2b-45e2-e9b4-041b074a4240"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "from moviepy.editor import VideoFileClip\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3055616/45929032 bytes (6.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6512640/45929032 bytes (14.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10010624/45929032 bytes (21.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13336576/45929032 bytes (29.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16859136/45929032 bytes (36.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20406272/45929032 bytes (44.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23871488/45929032 bytes (52.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27557888/45929032 bytes (60.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31145984/45929032 bytes (67.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34783232/45929032 bytes (75.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38182912/45929032 bytes (83.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41721856/45929032 bytes (90.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45244416/45929032 bytes (98.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrf1wzlSg4wa"
      },
      "source": [
        "Apply frame masking and find region of interest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3oFT5ekg9DO"
      },
      "source": [
        "def interested_region(img, vertices):\n",
        "    if len(img.shape) > 2: \n",
        "        mask_color_ignore = (255,) * img.shape[2]\n",
        "    else:\n",
        "        mask_color_ignore = 255\n",
        "        \n",
        "    cv2.fillPoly(np.zeros_like(img), vertices, mask_color_ignore)\n",
        "    return cv2.bitwise_and(img, np.zeros_like(img))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91iB2i_fhBsh"
      },
      "source": [
        " Conversion of pixels to a line in Hough Transform space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we285pxKhK4w"
      },
      "source": [
        "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
        "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
        "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "    lines_drawn(line_img,lines)\n",
        "    return line_img"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un29FI_ohPGs"
      },
      "source": [
        "Create two lines in each frame after Hough transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyJwfX6QhSv9"
      },
      "source": [
        "def lines_drawn(img, lines, color=[255, 0, 0], thickness=6):\n",
        "    global cache\n",
        "    global first_frame\n",
        "    slope_l, slope_r = [],[]\n",
        "    lane_l,lane_r = [],[]\n",
        "\n",
        "    α =0.2 \n",
        "    for line in lines:\n",
        "        for x1,y1,x2,y2 in line:\n",
        "            slope = (y2-y1)/(x2-x1)\n",
        "            if slope > 0.4:\n",
        "                slope_r.append(slope)\n",
        "                lane_r.append(line)\n",
        "            elif slope < -0.4:\n",
        "                slope_l.append(slope)\n",
        "                lane_l.append(line)\n",
        "        img.shape[0] = min(y1,y2,img.shape[0])\n",
        "    if((len(lane_l) == 0) or (len(lane_r) == 0)):\n",
        "        print ('no lane detected')\n",
        "        return 1\n",
        "    slope_mean_l = np.mean(slope_l,axis =0)\n",
        "    slope_mean_r = np.mean(slope_r,axis =0)\n",
        "    mean_l = np.mean(np.array(lane_l),axis=0)\n",
        "    mean_r = np.mean(np.array(lane_r),axis=0)\n",
        "    \n",
        "    if ((slope_mean_r == 0) or (slope_mean_l == 0 )):\n",
        "        print('dividing by zero')\n",
        "        return 1\n",
        "    \n",
        "    x1_l = int((img.shape[0] - mean_l[0][1] - (slope_mean_l * mean_l[0][0]))/slope_mean_l) \n",
        "    x2_l = int((img.shape[0] - mean_l[0][1] - (slope_mean_l * mean_l[0][0]))/slope_mean_l)   \n",
        "    x1_r = int((img.shape[0] - mean_r[0][1] - (slope_mean_r * mean_r[0][0]))/slope_mean_r)\n",
        "    x2_r = int((img.shape[0] - mean_r[0][1] - (slope_mean_r * mean_r[0][0]))/slope_mean_r)\n",
        "    \n",
        "   \n",
        "    if x1_l > x1_r:\n",
        "        x1_l = int((x1_l+x1_r)/2)\n",
        "        x1_r = x1_l\n",
        "        y1_l = int((slope_mean_l * x1_l ) + mean_l[0][1] - (slope_mean_l * mean_l[0][0]))\n",
        "        y1_r = int((slope_mean_r * x1_r ) + mean_r[0][1] - (slope_mean_r * mean_r[0][0]))\n",
        "        y2_l = int((slope_mean_l * x2_l ) + mean_l[0][1] - (slope_mean_l * mean_l[0][0]))\n",
        "        y2_r = int((slope_mean_r * x2_r ) + mean_r[0][1] - (slope_mean_r * mean_r[0][0]))\n",
        "    else:\n",
        "        y1_l = img.shape[0]\n",
        "        y2_l = img.shape[0]\n",
        "        y1_r = img.shape[0]\n",
        "        y2_r = img.shape[0]\n",
        "      \n",
        "    present_frame = np.array([x1_l,y1_l,x2_l,y2_l,x1_r,y1_r,x2_r,y2_r],dtype =\"float32\")\n",
        "    \n",
        "    if first_frame == 1:\n",
        "        next_frame = present_frame        \n",
        "        first_frame = 0        \n",
        "    else :\n",
        "        prev_frame = cache\n",
        "        next_frame = (1-α)*prev_frame+α*present_frame\n",
        "              \n",
        "    cv2.line(img, (int(next_frame[0]), int(next_frame[1])), (int(next_frame[2]),int(next_frame[3])), color, thickness)\n",
        "    cv2.line(img, (int(next_frame[4]), int(next_frame[5])), (int(next_frame[6]),int(next_frame[7])), color, thickness)\n",
        "    \n",
        "    cache = next_frame"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjP4iv44sgJF"
      },
      "source": [
        "Process each frame of video to detect lane"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lb2s5XKsidn"
      },
      "source": [
        "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
        "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
        "\n",
        "\n",
        "def process_image(image):\n",
        "\n",
        "    global first_frame\n",
        "\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    img_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "\n",
        "    lower_yellow = np.array([20, 100, 100], dtype = \"uint8\")\n",
        "    upper_yellow = np.array([30, 255, 255], dtype=\"uint8\")\n",
        "\n",
        "    mask_yellow = cv2.inRange(img_hsv, lower_yellow, upper_yellow)\n",
        "    mask_white = cv2.inRange(gray_image, 200, 255)\n",
        "    mask_yw = cv2.bitwise_or(mask_white, mask_yellow)\n",
        "    mask_yw_image = cv2.bitwise_and(gray_image, mask_yw)\n",
        "\n",
        "    gauss_gray= cv2.GaussianBlur(mask_yw_image, (5, 5), 0)\n",
        "\n",
        "    canny_edges=cv2.Canny(gauss_gray, 50, 150)\n",
        "\n",
        "    imshape = image.shape\n",
        "    lower_left = [imshape[1]/9,imshape[0]]\n",
        "    lower_right = [imshape[1]-imshape[1]/9,imshape[0]]\n",
        "    top_left = [imshape[1]/2-imshape[1]/8,imshape[0]/2+imshape[0]/10]\n",
        "    top_right = [imshape[1]/2+imshape[1]/8,imshape[0]/2+imshape[0]/10]\n",
        "    vertices = [np.array([lower_left,top_left,top_right,lower_right],dtype=np.int32)]\n",
        "    roi_image = interested_region(canny_edges, vertices)\n",
        "\n",
        "    theta = np.pi/180\n",
        "\n",
        "    line_image = hough_lines(roi_image, 4, theta, 30, 100, 180)\n",
        "    result = weighted_img(line_image, image, α=0.8, β=1., λ=0.)\n",
        "    return result"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}